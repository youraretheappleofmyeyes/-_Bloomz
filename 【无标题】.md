# 学习目标：

`基于LLM-factory 训练Bloomz-7B医疗模型

例如：

 - [ ] 增量预训练
 - [ ] STF微调
 - [ ] 直接偏好优化DPO
 - [ ] 量化
 - [ ] 部署

---

# 学习内容：

`提示：这里可以添加要学的内容`
开源数据集：
|SFT数据集|  |	
|--|--|
| HuatuoGPT-sft-data-v1 | [地址](https://huggingface.co/datasets/FreedomIntelligence/HuatuoGPT-sft-data-v1) |
|Chinese-medical-dialogue-data|[中文医疗科室问答数据](https://github.com/Toyhom/Chinese-medical-dialogue-data)|
| Huatuo26M-Lite | [Huatuo-Lite](https://huggingface.co/datasets/FreedomIntelligence/Huatuo26M-Lite) |
|DISC-Med-SFT|[中文医疗多轮对话数据](https://huggingface.co/datasets/Flmc/DISC-Med-SFT)|
|sft-20k.json|[疾病、药品知识问答](https://github.com/CMKRG/QiZhenGPT/blob/main/data/train/sft-20k.json)|
|ShenNong_TCM_Dataset|[中文医疗问答数据](https://huggingface.co/datasets/michaelwzhu/ShenNong_TCM_Dataset)|
|Medical-Dialogue-System|[中/英医疗多轮对话数据集](https://github.com/UCSD-AI4H/Medical-Dialogue-System)|
|DPO||
|dpo_zh_500.jsonl|[地址](https://github.com/shibing624/MedicalGPT/tree/main/data/reward)|
|DPO-En-Zh-20k-Preference|[地址](https://huggingface.co/datasets/shibing624/DPO-En-Zh-20k-Preference)|

微调数据集配比：
参考：
贝壳团队做的关于大模型在垂域上继续finetune时的一些实验情况
ChatHome: Development and Evaluation of a Domain-Specific Language Model for Home Renovation
预训练数据配比：
![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/8d0e51db5e464886a6a538a2874c62e1.png#pic_center)

SFT数据配比：
![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/a01f6e2a5a8e444b80c6f790d12bb9bc.png#pic_center)

高质量微调数据集筛选：
参考：
1. [IFD](https://github.com/MingLiiii/Cherry_LLM)
3. [MODS](https://github.com/CASIA-LM/MoDS)
4. [CaR](https://github.com/IronBeliever/CaR/tree/main)
5. [GPT-4/ChatGPT模型蒸馏医学数据](https://huggingface.co/spaces/wangrongsheng/DataMaker)

---

# 学习时间：

`提示：这里可以添加计划学习的时间`

例如：

 - 周一至周五晚上 7 点—晚上9点
 - 周六上午 9 点-上午 11 点
 - 周日下午 3 点-下午 6 点

---

# 学习产出：

`提示：这里统计学习计划的总量`

例如：

 - [x] 技术笔记 2 遍
 - [x] CSDN 技术博客 3 篇
 - [x] 习的 vlog 视频 1 个
